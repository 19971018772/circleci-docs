---

description: コンテナランナーのオープンプレビュー
contentTags:
  platform:
  - クラウド
---
= コンテナランナーのオープンプレビュー
:page-layout: classic-docs
:page-liquid:
:icons: font
:toc: macro
:toc-title:

こちらは、 **オープンプレビュー** でご利用いただけるようになった、CircleCI の新しいタイプのセルフホストランナーに関するドキュメントです。

[#introduction-and-motivation]
== 概要と経緯

CircleCI の <<runner-overview#,セルフホストランナー>> はこれまで、CI ジョブとセルフホストランナーのバイナリがインストールされた <<configuration-reference#machine,マシン>> 環境 (仮想または物理的な) を 1 対 1 でマッピングして各ジョブを実行していました。 この方法でジョブを排他的に実行すると、<<using-docker#,Docker Executor>> の使用時に CircleCI のクラウドで提供されている次のようなコンテナベースソリューションのメリットが失われます。

* ジョブ実行時に、カスタム Docker イメージをシームレスに定義、パブリッシュ、使用する機能
* `.circleci/config.yml` のステップで依存関係を列挙せずに、カスタム Docker イメージを使って依存関係やライブラリを簡単に管理する機能
* 一貫性のあるクリーンなコンテナ化されたビルド環境へのすべてのジョブにおけるアクセス

コンテナランナーは、現在オープンプレビューでご利用いただける機能です。これを Kubernetes (k8s) クラスタにインストールすると、ネイティブな Docker Executor を使用するジョブを CircleCI のクラウドプラットフォームで実行するのと同じように、コンテナ化した CI ジョブをセルフホストコンピューティング環境で実行できます。

コンテナランナーはマシンランナーの補完機能であり、代替機能ではありません。

コンテナエージェントのバイナリをインストールすると、コンテナエージェントは Docker ジョブを要求し、それらを一時的な Pod 内でスケジュール化し、コンテナベースの実行環境で処理を実行します。

.コンテナエージェントモデル -多数のコンテナエージェントとタスクエージェント
image::container-runner-model.png[Container-agent model]

[#running-container-runner-first-job]
== コンテナランナーの最初のジョブの実行

WARNING: この機能はプレビュー期間であるため、注意してご使用ください。

ランナーの <<runner-concepts#namespaces-and-resource-classes,リソースクラス>> と関連するリソースクラストークンの <<runner-installation#circleci-web-app-installation,作成>> これは、CircleCI Web アプリ (推奨) または <<runner-installation-cli#,CircleCI CLI>> を使って行えます。

[#preqrequisites]
=== 前提条件

* Kubernetes 1.12 以上
* Helm 3.x
* ランナーのリソースクラストークン
* コンテナランナーが、他のワークロードがない状態で、Kubernetes 名前空間で実行されていること (ランナーまたはガベージコレクション (GC) によって、同じ名前空間内のジョブが削除される可能性があるため)
* `checkout` ステップで、SSH でチェックアウトするように git が設定されていること。 これを使用する場合は、ポート 22 からのアウトバウンド接続を許可するようにクラスタが設定されていることを確認してください。

[#installing-the-helm-chart]
=== Helm チャートのインストール

NOTE: 下記の手順は、オープンプレビュー中に変更される可能性があります。

`container-agent` というリリース名で Helm チャートをインストールします。

* `helm repo add circleci https://circleci-binary-releases.s3.amazonaws.com/charts/` を実行します。
*  `helm repo update` を実行します。
*  `helm install container-agent circleci/container-agent -n circleci` を実行し、チャートをインストールします。

これにより、コンテナエージェントが `container-agent` というリリース名で Kubernetes クラスタにデプロイされます。 `helm show values circleci/container-agent` を実行するとデフォルト値を確認できます。これらを、以下の install コマンドに `--values` フラグまたは `--set name=value` フラグを指定することで上書きします。

[#update-values.yaml]
=== values.yaml の更新

カスタマイズなしでジョブを実行するには、次の設定を Helm チャートの `values.yaml` に追加します。 `MY_TOKEN` は、ランナーのリソースクラストークンです。 ご自身の名前空間とランナーリソースクラスで `namespace/my-rc` を更新します。

```yaml
agent:
  resourceClasses:
    namespace/my-rc:
      token: MY_TOKEN
```

[#trigger-a-job]
=== ジョブのトリガー

クラスタにコンテナランナーをインストールしたら、Docker Executor を使ってインストールを検証する CircleCI ジョブを作成し、トリガーします。

- `circleci/config.yml` ファイルで、 <<using-docker#,Docker Executor 構文>> を、コンテナランナーのインストールの `resourceClasses` セクションに含めたリソースクラスと組み合わせて使用します。
- 具体的には、クラスタ内のコンテナランナーを使って実行されるようジョブをルーティングし、コンテナランナーのジョブ用に作成したリソースクラスを使用するようにリソースクラスのスタンザを更新します。
+
```YAML
resource_class: <namespace>/<name-of-resource-class-created>
```

NOTE: <<building-docker-images#,setup_remote_docker>> を使用する既存のジョブは**使用しないでください** (詳細は以下の <<#building-container-images,コンテナイメージのビルド>> のセクションを参照)。

設定ファイルを更新したら、ジョブが正常に実行されたかどうかを実際にトリガーして検証し、CircleCI Web アプリを使ってグリーンビルド (成功したビルド) であることを確認します。 See the link:/docs/runner-faqs#container-runner-specific-faqs[Runner FAQ page] for a full sample config if you are starting from scratch.

[#resource-class-configuration-custom-pod]
=== リソースクラスの設定とカスタマイズされたタスク Pod の設定

コンテナランナーでは、複数のリソースクラスから同時にタスクを要求または実行できます。また、特定のリソースクラス用のタスクを実行するために作成された Kubernetes リソースをカスタマイズすることもできます。 設定は、Helm チャート `values.yaml` にあるマップオブジェクトによって提供されます。

各リソースクラスは、次のパラメーターをサポートしています。

- `token`: タスクを要求するために使用される、ランナーのリソースクラストークン (**必須**)
- CircleCI ジョブの実行に使用するポッド用のカスタマイズされた Kubernetes Pod 設定

この Pod の設定は、通常の link:https://kubernetes.io/docs/reference/kubernetes-api/workload-resources/pod-v1/#debugging[Kubernetes Pod] 用のフィールドをすべて取得します。 サービスコンテナが CircleCI ジョブで使用される場合、最初の `container` 仕様が、タスク Pod 内のすべてのコンテナに使用されます。 現在、サービスコンテナとメインタスクコンテナで異なるコンテナ設定を使用することはできません。

以下は、タスクが正しく機能し、CircleCI 設定が問題なく動作するように、コンテナランナーによって上書きされるフィールドです。

- `spec.containers[0].name`
- `spec.containers[0].container.image`
- `spec.containers[0].container.args`
- `spec.containers[0].container.command`
- `spec.containers[0].container.workingDir`
- `spec.restartPolicy`
- `metadata.name`
- `metadata.namespace`

以下は、2 つのリソースクラスを使用した設定ファイルのフルサンプルです。

```yaml
agent:
  resourceClasses:
    circleci-runner/resourceClass:
      token: TOKEN1
      metadata:
        annotations:
          custom.io: my-annotation
      spec:
        containers:
          - resources:
              limits:
                cpu: 500m
            volumeMounts:
              - name: xyz
                mountPath: /path/to/mount
        securityContext:
          runAsNonRoot: true
        imagePullSecrets:
          - name: my_cred
        volumes:
          - name: xyz
            emptyDir: {}

    circleci-runner/resourceClass2:
      token: TOKEN2
      spec:
        imagePullSecrets:
          - name: "other"
```

[#custom-secret]
=== Custom token secret

Using the configuration described above provisions a Kubernetes secret containing your resource class tokens. In some circumstances, you may wish to provision your own secret, or you simply might not want to specify the tokens via helm. Instead, you can provision your own Kubernetes secret containing your tokens and specify its name in the `agent.customSecret` field.

The secret should contain a field for each resource class, using the resource class name as the key and the token as the value. Consider the following `resourceClasses` configuration:

```yaml
agent:
  resourceClasses:
    circleci-runner/resourceClass:
      metadata:
        annotations:
          custom.io: <my-annotation>

    circleci-runner/resourceClass2:
```

The corresponding custom secret would have 2 fields:

```yaml
circleci-runner.resourceClass: <my-token>
circleci-runner.resourceClass2: <my-token-2>
```

Due to Kubernetes secret key character constraints, the `/` separating the namespace and resouce class name is replaced with a `.` character. Other than this, the name must exactly match the `resourceClasses` config to match the token with the correct configuration.

Even if there is no further pod configuration, the resource class must be present in `resourceClasses` as an emtpy map, as shown by `circleci-runner/resourceClass2` in the above config example.

[#parameters]
=== Helm Chart Parameters

The following are **CircleCI specific settings**:

[.table.table-striped]
[cols=3*, options="header", stripes=even]
|===
|Parameter
|Description
|Default

|agent.runnerAPI
|Runner API URL
|https://runner.circleci.com

|agent.name
|A (preferably) unique name assigned to this particular `container-agent` instance. This name will appear in your Runner Inventory page in the CircleCI UI. If left unspecified, the name will default to the name of the deployment.
|`container-agent` (the name of the deployment)

|agent.resourceClasses *Default must be updated in order to run a job successfully*
|Resource class task configuration. See the "<<resource-class-configuration-custom-pod,Resource Class Configuration>>" section above.
|{}

|agent.customSecret
|A user provided Kubernetes containing resource class tokens. See the "<<custom-secret,Custom Token Secret>>" section above.
|""

|agent.terminationGracePeriodSeconds
|Termination grace period during container runner shutdown
|18300

|agent.maxRunTime
|Max task run time. This value should be shorter than the grace period above - See <<runner-config-reference/#runner-max_run_time#, docs>> for potential values
|5h

|agent.maxConcurrentTasks
|Maximum number of tasks claimed/run concurrently
|20

|agent.kubeGCEnabled
|Option to enabled/disable garbage collection
|true

|agent.kubeGCThreshold
|Length of time pods can run before deleted by GC
|5h5m

|agent.constraintChecker.enable
|Whether to enable the constraint checker
|false

|agent.constraintChecker.threshold
|Number of failed checks before disabling resource class claim
|3

|agent.constraintChecker.interval
|The constraint check interval
|15m
|===

---

The following is for **Kubernetes object settings**. All settings prefixed with `agent` below are for the container runner pod itself, not the ephemeral pods where jobs are executed.

[.table.table-striped]
[cols=3*, options="header", stripes=even]
|===
|Parameter
|Description
|Default

|nameOverride
|Override the chart name
|""

|fullnameOverride
|Override the full generated name
|""

|agent.replicaCount
|Number of container-agents to deploy. The recommendation is to leave this value at 1
|1

|agent.image.registry
|Agent image registry
|""

|agent.image.repository
|Agent image repository
|circleci/container-agent

|agent.pullPolicy
|Agent image pull policy
|Always

|agent.tag
|Agent image tag
|latest

|agent.pullSecrets
|link:https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/[Secret objects] container private registry credentials for the container runner pod itself, not the ephemeral pods that execute tasks
|[]

|agent.matchLabels
|Match labels used on agent pods
|app: container-agent

|agent.podAnnotations
|Extra annotations added to agent pods
|{}

|agent.podSecurityContext
|Security context policies added to agent pods
|{}

|agent.containerSecurityContext
|Security context policies add to agent containers
|{}

|agent.resources
|Custom resource specifications for container runner pods
|{}

|agent.nodeSelector
|Node selector for agent pods
|{}

|agent.tolerations
|Node tolerations for agent pods
|{}

|agent.tolerations
|Node tolerations for agent pods
|[]

|agent.affinity
|Node affinity for agent pods
|{}

|serviceAccount.create
|Create a custom service account for the agent
|true

|rbac.create
|Create a Role and RoleBinding for the service account
|true
|===

Container runner needs the following Kubernetes permissions:

* Pods, Pods/Exec, Pods/Log
** Get
** Watch
** List
** Create
** Delete
* Secrets
** List
** Create
** Delete

By default a `Role`, `RoleBinding` and service account are created and attached to the container runner pod, but if you customize these, the above are the minimum required permissions.

It is assumed that the container runner is running in a Kubernetes namespace without any other workloads. It is possible that the agent or garbage collection (GC) could delete pods in the same namespace.

[#garbage-collection]
== ガベージコレクション

各コンテナランナーは、クラスタに残ったままの、 `app.kubernetes.io/managed-by=circleci-container-agent` というラベルが付いた Pod やシークレットを削除するガベージコレクタを備えています。 デフォルトでは、これによって、5 時間 5 分を経過したジョブがすべて削除されます。 この時間は `agent.kubeGCThreshold` パラメーターを使って短くも長くもできます。 ただし、ガベージコレクション (GC) の頻度を下げた場合は、 `agent.maxRunTime` パラメーターの値を GC の頻度より小さくして、タスクの最大実行時間も短くしてください。 そうしないと、実行中のタスク Pod が GC によって削除されてしまう場合があります。

コンテナランナーは、終了シグナルを送信すると、ドレインして再起動します。 現時点のオープンプレビューでは、コンテナランナーが、起動に失敗したタスクを自動的にローンチしようとすることはありません。 これは、CircleCI Web アプリで行えます。

現時点では、コンテナランナーがクラッシュすると、処理中またはキューで待機中のタスクが安全に処理されることは期待できません。 オープンプレビューの今後の過程で、クラッシュ時の対処方法が追加され、文書化される予定です。

[#constraint-validation]
== 制約の確認

コンテナランナーを使用すると、Kubernetes の設定がすべて行われたタスク Pod を設定できます。 つまり、Pod が制約によりスケジュールできないように設定されている場合があります。 この解決策として、コンテナランナーには、Pod をスケジュールできるようクラスタの現在の状態と各リソースクラスの設定を定期的に確認する制約チェッカーが備わっています。 これにより、コンテナランナーがスケジュールできないジョブを要求し、失敗するのを防ぐことができます。

制約チェッカーによるチェックの失敗が多すぎた場合、再びチェックをパスするようになるまでそのリソースクラスの要求は無効になります。

現在、クラスタの状態に対して以下の制約のチェックを行っています。

* link:https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#nodeselector[Node Selector]
* link:https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#nodename[Node 名]
* link:https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#nodename[Node Affinity] - MatchExpressions  がチェックされる場合のみ

この機能の例として、以下のリソースクラスの設定ファイルを検討してみましょう。

```yaml
agent:
  resourceClasses:
    circleci-runner/resourceClass:
      token: TOKEN1
      spec:
        nodeSelector:
          disktype: ssd

    circleci-runner/resourceClass2:
      token: TOKEN2
```

1 つ目のリソースクラスには 、SSD を持つ Node にスケジュールされるようにする Node Selector が含まれています。 運用中に何らかの理由で、クラスタにそのラベルの Node がなくなったとします。 すると制約チェッカーは `circleci-runner/resourceClass` のチェックに失敗し、再び正しいラベルの Node が見つかるまでジョブの要求を無効にします。 各リソースクラスのチェックは互いに独立しているため、`circleci-runner/resourceClass2` の要求への影響はありません。

[#cost-and-availability]
== 料金と提供プラン

コンテナランナーのジョブは <<persist-data#managing-network-and-storage-use,ランナーネットワーク通信>> の対象です。 これは、セルフホストランナーの既存の料金モデルに沿っており、今後は、CircleCI の他のネットワークやストレージの料金設定にも合わせていく予定です。 ご不明な点がありましたら、CircleCI の担当者にお問い合わせください。

各プランのセルフホストランナーの link:https://circleci.com/ja/pricing/#comparison-table[同時実行制限] と同じ設定が、コンテナランナーのオープンプレビューにも適用されます。 最終的な料金設定と提供プランは、一般公開が近づきましたらご案内いたします。

[#building-container-images]
== コンテナイメージのビルド

link:https://docs.gitlab.com/ee/ci/docker/using_docker_build.html#use-docker-in-docker[Docker in Docker] は、クラスタに対するセキュリティリスクを招く可能性があるため推奨されません。

コンテナエージェントジョブでコンテナイメージをビルドするには、以下を使用できます。

1. Buildah などのサードパーティー製ツール
1. Docker がインストールされたマシンランナー
1. CircleCI がホストするコンピューティング環境

注: サードパーティ製ツールはお客様の判断でご使用ください。

コンテナエージェントで実行されるジョブでは CircleCI の <<building-docker-images#,setup_remote_docker>> 機能は使用できませんが、Docker デーモンを使わずにコンテナエージェントジョブでサードパーティー製ツールを使って Docker  イメージをビルドすることができます。

シンプルな方法は、 link:https://github.com/containers/buildah[Buildah] というツールの使用です。 Buildah は `.circleci/config.yml` 構文内で使用できます。

```yaml
docker:
  - image: quay.io/buildah/stable
```

[#using-the-buildah-image]
=== Buildah の使用

Buildah は、コンテナ内の link:https://github.com/containers/fuse-overlayfs[fuse-overlay] プログラムに依存します。つまり、使用するにはヒューズデバイスプラグインを設定する必要があります。 このオプションでは、Buildah を使用するためにコンテナに `/dev/fuse` を追加するようホスト上の Buildah に指示するため、コンテナ内で `fuse-overlayfs` を使用するには `/dev/fuse` が必要です。 Kubernetes にはホストデバイスを安全にシェアできるデバイスプラグインシステムが備わっています。

`dev/fuse` の設定をインストールするには、link:https://github.com/kuberenetes-learning-group/fuse-device-plugin/blob/master/fuse-device-plugin-k8s-1.16.yml[このリポジトリ] をコンテナエージェントのデプロイで Helm コマンドを実行している場所にクローンします。 次に、下記を実行します。

```
kubectl create -f fuse-device-plugin-k8s-1.16.yml
```

`kubectl get daemonset -n kube-system` を実行し、`fuse-device-plugin-daemonset` があることが確認できれば、この構成は正しく設定されています。

このデバイスが追加されたら、コンテナエージェントの <<#resource-class-configuration-custom-pod,リソースクラスの設定>> を更新します。

```yaml
resourceClasses:
 <namespace>/<resourceClass>:
  token: <token>
   spec:
    containers:
     - resources:
        limits:
         github.com/fuse: 1
```

これで、コンテナエージェントジョブで Buildah コマンドを実行し、コンテナをビルドできるようになります。 

```yaml
  docker-image:
    docker:
      - image: quay.io/buildah/stable
    resource_class: <namespace>/<resourceClass>
    steps:
      - checkout
      - run:
          name: sanity-test
          command: |
            buildah version
      - run:
          name: Building-a-container
          command: |
            buildah bud -f ./Dockerfile -t myimage:0.1
            buildah push myimage:tag
```

[#using-buildah-with-custom-images]
=== カスタムイメージでの Buildah の使用

独自のカスタムイメージをビルドし、Dockerfile に Buildah のインストールを含めることもできます。

```
sudo yum install buildah
```

link:https://circleci.com/developer/images[CircleCI イメージ] を使用する場合は、インストール用のリポジトリをジョブの `steps` に追加してください。

```
sudo apt-get update
sudo apt-get install -y wget ca-certificates gnupg2
VERSION_ID=$(lsb_release -r | cut -f2)
echo "deb http://download.opensuse.org/repositories/devel:/kubic:/libcontainers:/stable/xUbuntu_${VERSION_ID}/ /" | sudo tee /etc/apt/sources.list.d/devel-kubic-libcontainers-stable.list
curl -Ls https://download.opensuse.org/repositories/devel:kubic:libcontainers:stable/xUbuntu_$VERSION_ID/Release.key | sudo apt-key add -
sudo apt-get update
sudo apt install buildah -y
```

次に、`BUILDAH_ISOLATION` に `chroot` を指定します。

```
# Default to isolate the filesystem with chroot.
ENV BUILDAH_ISOLATION=chroot
```

次に、 上記の <<#using-the-buildah-image,Buildah イメージの使用>> と同じ手順でヒューズディバイスプラグインをコンテナエージェントのデプロイに追加し、これらのジョブでカスタムイメージを使用してコンテナイメージをビルドするよう `.circleci/config.yml` ファイルを更新します。

[#limitations]
== 制限事項

コンテナランナーは現在プレビュー段階であり、いくつかの制限事項があります。 下記リストには、すべての制限ではなく重要な制限のみが記載されています。 下記内容は変更される場合があり、現時点ではサポートされていない機能も今後サポートされる場合があります。

* SSH を使用したジョブの再実行
* 既存のセルフホストランナーに対する現在の <<runner-overview#limitations,制限事項>> は、コンテナエージェントにも引き続き適用されます。
* Kubernetes を除き、コンテナ環境のサポートは現時点ではありません。
* Web アプリでの UI ベースのインストールフローによるコンテナランナーのインストールはサポートしていません。ただし、コンテナランナーで使用できる、ランナーのリソースクラスの作成は例外です。
* コンテナランナーは link:https://circleci.com/ja/pricing/server/[CircleCI Server] ではまだ動作しません。
* <<building-docker-images#,`setup_remote_docker`>> as a command is not supported with container runner.  See <<#building-container-images,Building Container Images>>.

[#how-to-receive-technical-help]
== 技術サポートを受けるには

CircleCI の担当者に直接ご連絡いただくか、 link:https://discuss.circleci.com/t/a-more-scalable-container-friendly-self-hosted-runner-container-agent-now-in-open-preview/45094[Discuss の投稿] からお問い合わせください。

[#faqs]
== FAQ

コンテナランナーについてよくあるご質問については、 <<runner-faqs#container-runner-specific-faqs,ランナーについてのよくあるご質問のページ >> をご覧ください。