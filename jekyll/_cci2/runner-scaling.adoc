---
description: Learn how to scale CircleCI's self-hosted runners.
version:
- Cloud
- Server v4.x
- Server v3.x
---
= Scaling self-hosted runners
:page-layout: classic-docs
:page-liquid:
:icons: font
:toc: macro
:toc-title:
toc::[]

[#introduction]
== Introduction

Maintaining a fixed compute fleet for CircleCI's self-hosted runners can incur unnecessary costs as the workload can fluctuate depending on the rate at which jobs are queued. To help reduce this cost, the compute fleet can be scaled according to the demand.

You can view an example tutorial for scaling self-hosted runners with AWS AutoScaling groups on the link:https://circleci.com/blog/autoscale-self-hosted-runners-aws/[CircleCI blog].

[#spinning-up-more-pods-with-container-runner]
== Spinning up more pods with container runner

CircleCI scales self-hosted container runner by spinning up more pods when there are more jobs to be executed, and tears down those pods when the execution is complete. While pods will scale with the work automatically, CircleCI will _not_ go into your Kubernetes cluster and scale your compute.

[#scaling-data]
== Scaling data

There are several API endpoints to help you set up a solution to scale data:

* <<runner-api#get-apiv2runnertasks,Unclaimed Tasks>>
* <<runner-api#get-apiv2runnertasksrunning,Running Tasks>>
* <<runner-api#get-apiv2runner,List Resource Classes>>

A scaling solution can use the above endpoints to calculate the total number of waiting tasks which can be run. The task data endpoints are scoped to a single resource class, so it's important to query every available resource class to get the total number of running tasks. 

The scaling solution is then free to decide which resource class to add new claiming agents for. The distribution of tasks across resource classes is dependent on the incoming workload and internal dispatching decisions made by CircleCI.

NOTE: You will also need to be aware of your plan's concurrency limit to avoid starting compute which cannot be used. This can be found on the CircleCI https://circleci.com/pricing/[Plans page]. Scale plan customers will need to contact support to get this information.

[#agent-configuration]
== Agent configuration for machine runner

There are some machine runner configuration settings which can be used by your scaling solution, particularly to assist resource cleanup when the demand drops:

* <<runner-config-reference#runner-mode,Runner Mode>>
** Choosing `single-task` mode will cause machine runner to shut down after a single task. This is useful if using completely ephemeral compute as the resources can be automatically recycled upon machine runner exit.
** Choosing `continuous` mode will cause the machine runner to poll for new tasks after completing a task. Your scaling solution will need to monitor the task workload and actively shutdown unused machine runners.
* <<runner-config-reference#runner-idle_timeout,Runner Idle Timeout>>
** Setting a reasonable timeout can be used for automatic resource recycling during periods of lower demand.
