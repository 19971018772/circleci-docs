---
contentTags:
  platform:
    - Server v4.1
    - Server Admin
---
= Configuring External Services
:page-layout: classic-docs
:page-liquid:
:page-description: This document describes how to configure the following external services for use with a CircleCI server 4.x installation
:icons: font
:toc: macro
:toc-title:

This page describes how to configure external services for use with either a new CircleCI server v4.x installation or migrating internal Postgres and MongoDB data from existing CircleCI server v4.x installation to your externalized datastores.

toc::[]

[#postgresql]
== PostgreSQL

[#best-practices-for-your-postgresql]
=== Best practices for PostgreSQL

NOTE: Your externalized PostgreSQL instance needs to be version 12.1 or higher.

Consider running at least two PostgreSQL replicas to allow recovery from primary failure and for backups. The table below shows the recommended specifications for PostgreSQL machines:

[.table.table-striped]
[cols=6*, options="header", stripes=even]
|===
|# of Daily Active Users
|# of PostgreSQL Replicas
|CPU
|RAM
|Disk
|NIC Speed

|<50
|2
|8 Cores
|16 GB
|100 GB
| 1 Gbps

|50 - 250
|2
|8 Cores
|16 GB
|200 GB
|1 Gbps

|250 - 1000
|3
|8 Cores
|32 GB
|500 GB
|10 Gbps

|1000 - 5000
|3
|8 Cores
|32 GB
|1 TB
|10 Gbps

|5000+
|3
|8 Cores
|32 GB
|1 TB
|10 Gbps
|===


[#migrating-from-internal-postgres]
=== Migrating from an Internal Postgres to an Externalized Source

NOTE: If you are doing a fresh install of CircleCI Server, then you can skip this section and head to (link)[Connecting Your External Postgres Instance to CircleCI Server]

When a CircleCI Server instance deployed, Postgres is deployed internally by default via its helm chart. However as an operator, you may wish to externalize this database to have better control over it's scalability and availability. Once you have configured your external Postgres, you may use the guide below to migrate your Postgres data to your external database.

NOTE: This process requires downtime.

==== 1. Disable the application
We disable the CircleCI Server application by scaling down the application layer pods using the following command. No Data is lost in this process, but the application will be unreachable.
Scale down your application layer pods:

[source,shell]
----
namespace=<your-server-namespace>
kubectl -n "$namespace" scale deploy -l "layer=application" --replicas="0"
----

Running `kubectl -n "$namespace" get pods` should show most of your pods scaling to down, leaving your database pods running including postgres.

==== 2. Validate access to your External Postgres from within the Cluster (Optional)
Here we will confrim that pods within your CircleCI Server cluster can access your external Postgres. We will do this from within your internal Postgres.

[source,shell]
----
PG_POD=$(kubectl -n "$namespace" get pods | grep postgresql | tail -1 | awk '{print $1}')
kubectl exec -it -n "$namespace" "$PG_POD" -- bash
----

Then while still connected to the pod run:
[source,shell]
----
psql -h <your-external-postgres-host> -U postgres -p <your-external-postgres-port>
----

You should be able to connect to your external Postgres at this point. If not then please resolve any issues before proceeding. 
You may use `helm upgrade ...` to restore your CircleCI server instance to a running state.

==== 3. Generate export of your Internal Postgres
Retrieve your internal Postgres credentials:

[source,shell]
----
PG_PASSWORD=$(kubectl -n "$namespace" get secrets postgresql -o jsonpath="{.data.postgresql-password}" | base64 --decode)
----

NOTE: The username for your internal Postgres is `postgres`. The password is randomly generated unless directly set at installation.

Connect to Postgres pod and perform postgres dump
[source,shell]
----
kubectl -n "$namespace" exec -it "$PG_POD" -- bash -c "export PGPASSWORD='$PG_PASSWORD' && pg_dumpall -U postgres -c" > circle.sql
----

NOTE: This backup is created in the filesystem used by the postgres pod. If you wish to store it locally, you may use `kubectl cp -n "$namespace" "$PG_POD":circle.sql /local/dir/circle.sql`

Clean up the Postgres Dump:
Your internally deployed Postgres uses the username `postgres`, however during the restore, the postgres dump will drop all resources before trying to create new ones, including the `postgres` user.
We will access the postgres pod where the dump is stored and run the following commands on the postgres dump file to remove the lines that would delete the postgres user.

[source,shell]
----
PG_POD=$(kubectl -n "$namespace" get pods | grep postgresql | tail -1 | awk '{print $1}')
kubectl exec -it -n "$namespace" "$PG_POD" -- bash

sed -i".bak" '/DROP ROLE postgres/d' circle.sql
sed -i".bak" '/CREATE ROLE postgres/d' circle.sql
sed -i".bak" '/ALTER ROLE postgres WITH SUPERUSER INHERIT CREATEROLE CREATEDB LOGIN REPLICATION BYPASSRLS PASSWORD/d' circle.sql
----


==== 4. Restore your data in your External Postgres
While still connected to your the internally deployed Postgres, we will restore the dumped data to your external postgres

[source,shell]
----
psql -h <your-external-postgres-host> -U postgres -p <your-external-postgres-port> < circle.sql
----

Now your external Postgres will have your CircleCI Server data. In the next section we will update CircleCI server to Point to your external Postgres.


[#connecting-your-external-postgres]
=== Connecting Your External Postgres Instance to CircleCI Server

Once you have set up your external PostgreSQL instance, add the following to your `values.yaml` file for your CircleCI server instance to access it.

[source,yaml]
----
postgresql:
  internal: false
  postgresqlHost: <domain> # The domain or IP address of your PostgreSQL instance
  postgresqlPort: <port> # The port of your PostgreSQL instance
----

NOTE: `postgresql.internal: false` will remove any previously deployed Postgres instance deployed internally

[tab.postgres.Create_secret_yourself]
--
Create the secret and then add the following values to `values.yaml`:

[source,shell]
----
kubectl create secret generic postgresql \
  --from-literal=postgres-password=<postgres-password>
----

[source,yaml]
----
postgresql:
  ...
  auth:
    username: <username>
    existingSecret: postgresql
----
--

[tab.postgres.CircleCI_creates_secret]
--
Add the following to
the `values.yaml` file. CircleCI will create the secret automatically:

[source,yaml]
----
postgresql:
  ...
  auth:
    username: <username> # A user with the appropriate privileges to access your PostgreSQL instance.
    password: <password> # The password of the user account used to access your PostgreSQL instance.
----
--

The changes will take effect upon running `helm install/upgrade`. If you are completing a migration to an externalized Postgres instance then when you perform `helm upgrade`, the scaled down pods will be scaled back to their replica numbers as defined by your `values.yaml`.


[#backing-up-postgresql]
=== Backing Up PostgreSQL
PostgreSQL provides official documentation for backing up and restoring your PostgreSQL 12 install, which can be found https://www.postgresql.org/docs/12/backup.html[here].

We strongly recommend the following:

* Taking daily backups.
* Keeping at least 30 days of backups.
* Using encrypted storage for backups as databases might contain sensitive information.
* Performing a backup before each upgrade of CircleCI server.

[#mongodb]
== MongoDB

NOTE: If using your own MongoDB instance, it needs to be version 3.6 or higher.

[#migrating-from-internal-mongodb]
=== Migrating from an Internal MongoDB to an Externalized Source

NOTE: If you are doing a fresh install of CircleCI Server, then you can skip this section and head to (link)[Connecting Your External MongoDB Instance to CircleCI Server]

When a CircleCI Server instance deployed, MongoDB is deployed internally by default via its helm chart. However as an operator, you may wish to externalize this database to have better control over it's scalability and availability. Once you have configured your external MongoDB, you may use the guide below to migrate your Mongo data to your external database.

NOTE: This process requires downtime.

==== 1. Disable the application
We disable the CircleCI Server application by scaling down the application layer pods using the following command. No Data is lost in this process, but the application will be unreachable.
Scale down your application layer pods:

[source,shell]
----
namespace=<your-server-namespace>
kubectl -n "$namespace" scale deploy -l "layer=application" --replicas="0"
----

Running `kubectl -n "$namespace" get pods` should show most of your pods scaling to down, leaving your database pods running including mongo.

==== 2. Validate access to your External MongoDB from within the Cluster (Optional)
Here we will confrim that pods within your CircleCI Server cluster can access your external MongoDB. We will do this from within your internal MongoDB's pod.

[source,shell]
----
MONGO_POD="mongodb-0"
kubectl exec -it -n "$namespace" "$MONGO_POD" -- bash
----

Then while still connected to the pod run:
[source,shell]
----
mongo --username <username> --password --authenticationDatabase admin --host <external-mongodb-host> --port <external-mongodb-port>
----

You should be able to connect to your external MongoDB at this point. If not then please resolve any issues before proceeding. 
You may use `helm upgrade ...` to restore your CircleCI server instance to a running state.

==== 3. Generate export of your Internal MongoDB
Retrieve your internal MongoDB credentials:

[source,shell]
----
MONGO_POD="mongodb-0"
MONGODB_USERNAME="root"
MONGODB_PASSWORD=$(kubectl -n "$namespace" get secrets mongodb -o jsonpath="{.data.mongodb-root-password}" | base64 --decode)
----

Then create a backup directory in your MongoDB pod:
[source,shell]
----
kubectl -n "$namespace" exec "$MONGO_POD" -- mkdir -p /tmp/backups/
----

Generate a MongoDB database dump to the backup directory you just created:
[source,shell]
----
kubectl -n "$namespace" exec -it "$MONGO_POD" -- bash -c "mongodump -u '$MONGODB_USERNAME' -p '$MONGODB_PASSWORD' --authenticationDatabase admin --db=circle_ghe --out=/tmp/backups/"
----

==== 4. Restore your data in your External MongoDB
We can now use the generated MongoDB backup to restore the data to your external MongoDB:
[source,shell]
----
kubectl -n "$namespace" exec "$MONGO_POD" -- mongorestore --drop -u "$MONGODB_USERNAME" -p "$MONGODB_PASSWORD" --authenticationDatabase admin /tmp/backups/circle_ghe;
----

Now your external MongoDB will have your CircleCI Server data. In the next section we will update CircleCI server to Point to your external MongoDB.


[#connecting-your-external-mongodb]
=== Connecting Your External MongoDB Instance to CircleCI Server

Once you have configured your external MongoDB instance, add the following to your `values.yaml` file to connect your CircleCI Server instance.

[source,yaml]
----
mongodb:
  internal: false
  hosts: <hostname:port> # this can be a comma-separated list of multiple hosts for sharded instances
  ssl: <ssl-enabled>
  # If using an SSL connection with custom CA or self-signed certs, set this
  # to true
  tlsInsecure: false
  # Any other options you'd like to append to the MongoDB connection string.
  # Format as query string (key=value pairs, separated by &, special characters
  # need to be URL encoded)
  options: <additional-options>
  auth:
    database: <authentication-source-database
    mechanism: SCRAM-SHA-1
----

[tab.mongo.Create_secret_yourself]
--
Create the secret and then add the following values to `values.yaml`:

[source,shell]
----
kubectl create secret generic mongodb \
--from-literal=mongodb-root-password=<root-password> \
--from-literal=mongodb-password=dontmatter
----

[source,yaml]
----
mongodb:
  ...
  auth:
    ...
    username: <username>
    existingSecret: mongodb
----
--

[tab.mongo.CircleCI_creates_secret]
--
Add the following to
the `values.yaml` file. CircleCI will create the secret automatically:

[source,yaml]
----
mongodb:
  ...
  auth:
    ...
    username: <username>
    rootPassword: <root-password>
    password: <password>
----
--

The changes will take effect upon running `helm install/upgrade`. If you are completing a migration to an externalized MongoDB instance then when you perform `helm upgrade`, the scaled down pods will be scaled back to their replica numbers as defined by your `values.yaml`.