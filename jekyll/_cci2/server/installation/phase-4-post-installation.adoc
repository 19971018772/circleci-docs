---
version:
- Server v4.x
- Server Admin
---
= Phase 4 - Post installation
:page-layout: classic-docs
:page-liquid:
:icons: font
:toc: macro
:toc-title:

// This doc uses ifdef and ifndef directives to display or hide content specific to Google Cloud Storage (env-gcp) and AWS (env-aws). Currently, this affects only the generated PDFs. To ensure compatability with the Jekyll version, the directives test for logical opposites. For example, if the attribute is NOT env-aws, display this content. For more information, see https://docs.asciidoctor.org/asciidoc/latest/directives/ifdef-ifndef/.

Before you begin with the CircleCI server v4.x post installation phase, ensure you have run through link:/docs/server/installation/phase-1-prerequisites[Phase 1 – Prerequisites], link:/docs/server/installation/phase-2-core-services[Phase 2 - Core Services Installation] and link:/docs/server/installation/phase-3-execution-environments[Phase 3 - Execution Environments Installation].

.Installation Experience Flow Chart Phase 4
image::server-install-flow-chart-phase4.png[Flow chart showing the installation flow for server 3.x with phase 4 highlighted]

NOTE: In the following sections, replace any sections indicated by `< >` with your details.

toc::[]

[#backup-and-restore]
== Backup and restore

Backups of CircleCI server can be created through https://velero.io/[Velero]. You installed Velero in your cluster during the prerequisites installation phase.

// Don't include this section in the GCP PDF:

ifndef::env-gcp[]

[#set-up-backup-and-restore-on-aws]
=== Set up backup and restore on AWS

These instructions were sourced from the Velero documentation https://github.com/vmware-tanzu/velero-plugin-for-aws#setup[here].

. **Create an AWS S3 bucket**
+
[source,bash]
----
BUCKET=<YOUR_BUCKET>
REGION=<YOUR_REGION>
aws s3api create-bucket \
    --bucket $BUCKET \
    --region $REGION \
    --create-bucket-configuration LocationConstraint=$REGION
----
+
NOTE: `us-east-1` does not support a https://docs.aws.amazon.com/AmazonS3/latest/API/API_CreateBucket.html#API_CreateBucket_RequestBody[LocationConstraint]. If your region is `us-east-1`, omit the bucket configuration.

. **Set up permissions for Velero**
+
Create an IAM user:
+
[source,shell]
----
aws iam create-user --user-name velero
----
+
Attach policies to give user `velero` the necessary permissions:
+
[source,shell]
----
cat > velero-policy.json <<EOF
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Allow",
            "Action": [
                "ec2:DescribeVolumes",
                "ec2:DescribeSnapshots",
                "ec2:CreateTags",
                "ec2:CreateVolume",
                "ec2:CreateSnapshot",
                "ec2:DeleteSnapshot"
            ],
            "Resource": "*"
        },
        {
            "Effect": "Allow",
            "Action": [
                "s3:GetObject",
                "s3:DeleteObject",
                "s3:PutObject",
                "s3:AbortMultipartUpload",
                "s3:ListMultipartUploadParts"
            ],
            "Resource": [
                "arn:aws:s3:::${BUCKET}/*"
            ]
        },
        {
            "Effect": "Allow",
            "Action": [
                "s3:ListBucket"
            ],
            "Resource": [
                "arn:aws:s3:::${BUCKET}"
            ]
        }
    ]
}
EOF
----
+
[source,shell]
----
aws iam put-user-policy \
  --user-name velero \
  --policy-name velero \
  --policy-document file://velero-policy.json
----
+
Create an access key for user `velero`:
+
[source,shell]
----
aws iam create-access-key --user-name velero
----
+
The result should look like this:
+
[source,shell]
----
{
  "AccessKey": {
        "UserName": "velero",
        "Status": "Active",
        "CreateDate": "2017-07-31T22:24:41.576Z",
        "SecretAccessKey": <AWS_SECRET_ACCESS_KEY>,
        "AccessKeyId": <AWS_ACCESS_KEY_ID>
  }
}
----
+
Create a Velero-specific credentials file (for example: `./credentials-velero`) in your local directory, with the following contents:
+
[source,bash]
----
[default]
aws_access_key_id=<AWS_ACCESS_KEY_ID>
aws_secret_access_key=<AWS_SECRET_ACCESS_KEY>
----
+
TIP: the `AWS_ACCESS_KEY_ID` and `AWS_SECRET_ACCESS_KEY` placeholders are values returned from the `create-access-key` request in the previous step.

. **Install and start Velero**
+
Run the following `velero install` command. This creates a namespace called `velero` and installs all the necessary resources to run Velero.
Make sure that you pass the correct file name containing the AWS credentials that you created in step two.
+
NOTE: Backups require https://restic.net/[restic] to operate. When installing Velero, ensure that you have the `--use-restic` flag set, as shown below:
+
[source, bash]
----
velero install \
    --provider aws \
    --plugins velero/velero-plugin-for-aws:v1.2.0 \
    --bucket $BUCKET \
    --backup-location-config region=$REGION \
    --snapshot-location-config region=$REGION \
    --secret-file ./credentials-velero \
    --use-restic \
    --wait
----

. **Verify Velero**
+
Once Velero is installed on your cluster, check the new `velero` namespace. You should have a Velero deployment and a restic daemonset, for example:
+
[source,bash]
----
$ kubectl get pods --namespace velero
NAME                      READY   STATUS    RESTARTS   AGE
restic-5vlww              1/1     Running   0          2m
restic-94ptv              1/1     Running   0          2m
restic-ch6m9              1/1     Running   0          2m
restic-mknws              1/1     Running   0          2m
velero-68788b675c-dm2s7   1/1     Running   0          2m
----
+
TIP: As restic is a daemonset, there should be one pod for each node in your Kubernetes cluster.

// Stop hiding from GCP PDF:

endif::env-gcp[]

// Don't include this section in the AWS PDF:

ifndef::env-aws[]

[#set-up-backup-and-restore-on-gcp]
=== Set up backup and restore on GCP

These instructions were sourced from the documentation for the Velero GCP plugin https://github.com/vmware-tanzu/velero-plugin-for-gcp#setup[here].

. **Create a GCP bucket**
To reduce the risk of typos, you can set some of the parameters as shell variables. Should you be unable to complete all the steps in the same session, do not forget to reset variables as necessary before proceeding. In the step below, for example, you can define a variable for your bucket name. Replace the `<YOUR_BUCKET>` placeholder with the name of the bucket you want to create for your backups.
+
[source,bash]
----
BUCKET=<YOUR_BUCKET>

gsutil mb gs://$BUCKET/
----

. **Set up permissions for Velero**
+
CAUTION: If your server installation runs within a GKE cluster, ensure that your current IAM user is a cluster admin for this cluster, as RBAC objects need to be created. More information can be found in the https://cloud.google.com/kubernetes-engine/docs/how-to/role-based-access-control#iam-rolebinding-bootstrap[GKE documentation].

.. Set a shell variable for your project ID. Make sure that your `gcloud` CLI points to the correct project by looking at the current configuration:
+
[source,shell]
----
gcloud config list
----
+
If the project is correct, set the variable:
+
[source,shell]
----
PROJECT_ID=$(gcloud config get-value project)
----

.. Create a service account:
+
[source,shell]
----
gcloud iam service-accounts create velero \
    --display-name "Velero service account"
----
+
NOTE: If you run several clusters with Velero, consider using a more specific name for the Service Account besides `velero`, as suggested above.
+
You can check if the service account has been created successfully by running the following command:
+
[source,bash]
----
gcloud iam service-accounts list
----

.. Next, store the email address for the Service Account in a variable. Modify the command as needed to match the display name you have chosen for your Service Account:
+
[source,bash]
----
SERVICE_ACCOUNT_EMAIL=$(gcloud iam service-accounts list \
  --filter="displayName:Velero service account" \
  --format 'value(email)')
----
+
Grant the necessary permissions to the Service Account:
+
[source,bash]
----
ROLE_PERMISSIONS=(
    compute.disks.get
    compute.disks.create
    compute.disks.createSnapshot
    compute.snapshots.get
    compute.snapshots.create
    compute.snapshots.useReadOnly
    compute.snapshots.delete
    compute.zones.get
)

gcloud iam roles create velero.server \
    --project $PROJECT_ID \
    --title "Velero Server" \
    --permissions "$(IFS=","; echo "${ROLE_PERMISSIONS[*]}")"

gcloud projects add-iam-policy-binding $PROJECT_ID \
    --member serviceAccount:$SERVICE_ACCOUNT_EMAIL \
    --role projects/$PROJECT_ID/roles/velero.server

gsutil iam ch serviceAccount:$SERVICE_ACCOUNT_EMAIL:objectAdmin gs://${BUCKET}
----

.. Next, ensure that Velero can use this Service Account.

** **Option 1: JSON key file**
+
You can simply pass a JSON credentials file to Velero to authorize it to perform actions as the Service Account. To do this, you first need to create a key:
+
[source,bash]
----
gcloud iam service-accounts keys create credentials-velero \
    --iam-account $SERVICE_ACCOUNT_EMAIL
----
+
After running this command, you should see a file named `credentials-velero` in your local working directory.

** **Option 2: Workload Identities**
+
If you are already using https://cloud.google.com/kubernetes-engine/docs/how-to/workload-identity[Workload Identity] in your cluster, you can bind the GCP Service Account you just created to Velero's Kubernetes service account. In this case, the GCP Service Account needs the
`iam.serviceAccounts.signBlob` role in addition to the permissions already specified above.

. **Install and start Velero**
+
Run one of the following `velero install` commands, depending on how you authorized the service account. This creates a namespace called `velero` and installs all the necessary resources to run Velero.
+
NOTE: Backups require https://restic.net/[restic] to operate. When installing Velero, ensure that you have the `--use-restic` flag set.

** **using a JSON key file**
+
[source, bash]
----
velero install \
    --provider gcp \
    --plugins velero/velero-plugin-for-gcp:v1.2.0 \
    --bucket $BUCKET \
    --secret-file ./credentials-velero \
    --use-restic \
    --wait
----

** **using Workload Identities**
+
[source,bash]
----
velero install \
    --provider gcp \
    --plugins velero/velero-plugin-for-gcp:v1.2.0 \
    --bucket $BUCKET \
    --no-secret \
    --sa-annotations iam.gke.io/gcp-service-account=$SERVICE_ACCOUNT_EMAIL \
    --backup-location-config serviceAccount=$SERVICE_ACCOUNT_EMAIL \
    --use-restic \
    --wait
----
+
For more options on customizing your installation, refer to the https://github.com/vmware-tanzu/velero-plugin-for-gcp#install-and-start-velero[Velero documentation].

. **Verify Velero** 
+
Once Velero is installed on your cluster, check the new `velero` namespace. You should have a Velero deployment and a restic daemonset, for example:
+
[source,bash]
----
$ kubectl get pods --namespace velero
NAME                      READY   STATUS    RESTARTS   AGE
restic-5vlww              1/1     Running   0          2m
restic-94ptv              1/1     Running   0          2m
restic-ch6m9              1/1     Running   0          2m
restic-mknws              1/1     Running   0          2m
velero-68788b675c-dm2s7   1/1     Running   0          2m
----
+
TIP: As restic is a daemonset, there should be one pod for each node in your Kubernetes cluster.

endif::env-aws[]

////

* S3-COMPATIBLE SETUP *

////

[#set-up-backup-and-restore-with-s3-compatible-storage]
=== Set up backup and restore with S3-compatible storage

The following steps assume you are using S3-compatible object storage, but not necessarily AWS S3, for your backups.

These instructions were sourced from the Velero documentation https://velero.io/docs/v1.6/contributions/minio/[here].

. **Configure `mc` client**
+
To start, configure https://docs.min.io/minio/baremetal/reference/minio-mc.html[`mc`] to connect to your storage provider:
+
[source,bash]
----
# Alias can be any name as long as you use the same value in subsequent commands
export ALIAS=my-provider
mc alias set $ALIAS <YOUR_MINIO_ENDPOINT> <YOUR_MINIO_ACCESS_KEY_ID> <YOUR_MINIO_SECRET_ACCESS_KEY>
----
+
You can verify your client is correctly configured by running `mc ls my-provider` and you should see the buckets in your provider enumerated in the output.

. **Create a bucket**
+
Create a bucket for your backups. It is important that a new bucket is used, as Velero cannot use a preexisting bucket that contains other content.
+
[source, bash]
----
mc mb ${ALIAS}/<YOUR_BUCKET>
----

. **Create a user and policy**
+
Create a user and policy for Velero to access your bucket.
+
NOTE: In the following snippet `<YOUR_MINIO_ACCESS_KEY_ID>` and `<YOUR_MINIO_SECRET_ACCESS_KEY>` refer to the credentials used by Velero to access MinIO.
+
[source, bash]
----
# Create user
mc admin user add $ALIAS <YOUR_MINIO_ACCESS_KEY_ID> <YOUR_MINIO_SECRET_ACCESS_KEY>

# Create policy
cat > velero-policy.json << EOF
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Action": [
        "s3:*"
      ],
      "Resource": [
        "arn:aws:s3:::<YOUR_BUCKET>",
        "arn:aws:s3:::<YOUR_BUCKET>/*"
      ]
    }
  ]
}
EOF

mc admin policy add $ALIAS velero-policy velero-policy.json

# Bind user to policy
mc admin policy set $ALIAS velero-policy user=<YOUR_VELERO_ACCESS_KEY_ID>
----
+
Finally, you add your new user's credentials to a file (`./credentials-velero` in
this example) with the following contents:
+
[source,toml]
----
[default]
aws_access_key_id=<YOUR_VELERO_ACCESS_KEY_ID>
aws_secret_access_key=<YOUR_VELERO_SECRET_ACCESS_KEY>
----

. **Install and start Velero**
+
Run the following `velero install` command. This creates a namespace called `velero` and installs all the necessary resources to run Velero.
+
NOTE: Backups require https://restic.net/[restic] to operate. When installing Velero, ensure that you have the `--use-restic` flag set, as shown below:
+
[source, bash]
----
velero install --provider aws \
  --plugins velero/velero-plugin-for-aws:v1.2.0 \
  --bucket <YOUR_BUCKET> \
  --secret-file ./credentials-velero \
  --use-volume-snapshots=false \
  --use-restic \
  --backup-location-config region=minio,s3ForcePathStyle="true",s3Url=<YOUR_ENDPOINT> \
  --wait
----

. **Verify Velero**
+
Once Velero is installed on your cluster, check the new `velero` namespace. You
should have a Velero deployment and a restic daemonset, for example:
+
[source,bash]
----
$ kubectl get pods --namespace velero
NAME                      READY   STATUS    RESTARTS   AGE
restic-5vlww              1/1     Running   0          2m
restic-94ptv              1/1     Running   0          2m
restic-ch6m9              1/1     Running   0          2m
restic-mknws              1/1     Running   0          2m
velero-68788b675c-dm2s7   1/1     Running   0          2m
----
+
TIP: As restic is a daemonset, there should be one pod for each node in your Kubernetes cluster.

[#take-backup]
=== Take a backup
Now that Velero is installed on your cluster, you are ready to create your first backup. If you encounter problems, please refer to the
https://circleci.com/docs/2.0/server/operator/backup-and-restore/#troubleshooting[troubleshooting] section.

* To create the backup, run:
+
[source,bash]
----
K8S_NS=$(helm list -o yaml  | yq '.[].namespace')
CHART=$(helm list -o yaml  | yq '.[].chart' )
REV=$(helm list -o yaml  | yq '.[].revision')
RANDOM_STR=$(cat /dev/urandom | env LC_ALL=C tr -dc 'a-z0-9' | head -c 8)

velero backup create "${K8S_NS}-${RANDOM_STR}" --include-namespaces "${K8S_NS}" --labels "chart--rev=${CHART}--${REV}"
----

* To restore from a backup, run:
+
[source,bash]
----
# List all existing backups
velero backup get --show-labels

# Restore the specific backup
velero restore create --include-namespaces <circleci-namespace> --from-backup <backup-name>
----

See the https://velero.io/docs/v1.6/disaster-case/[Velero] documentation or more details.

[#email-notifications]
== Email Notifications

Add email notification support by adding the following to `values.yaml`:

[source,yaml]
----
smtp:
  host: <hostname-of-submission-server>
  user: <username-for-submission-server>
  password: <password-for-submission-server
  port: <mail-port>
----

[#managing-orbs]
== Managing orbs

Server installations include their own local orb registry. This registry is private to the server installation. All orbs referenced in project configs reference the orbs in the _server_ orb registry. You are responsible for maintaining orbs. This includes:

* Copying orbs from the public registry.
* Updating orbs that may have been copied previously.
* Registering your company's private orbs, if you have any.

For more information and steps to complete these tasks, see the link:/docs/server/operator/managing-orbs[Orbs on server guide].

[#all-values-yaml-options]
== All Helm values.yaml Options

[options="header"]
|===
|Key |Type |Default |Description
|apiToken
|string
|`""`
|API token (2 Options). Option 1: Set the value here and CircleCI will create the secret automatically. Option 2: Leave this blank, and create the secret yourself. CircleCI will assume it exists.
|api_service.replicas
|int
|`1`
|Number of replicas to deploy for the api-service deployment.
|audit_log_service.replicas
|int
|`1`
|Number of replicas to deploy for the audit-log-service deployment.
|branch_service.replicas
|int
|`1`
|Number of replicas to deploy for the branch-service deployment.
|builds_service.replicas
|int
|`1`
|Number of replicas to deploy for the builds-service deployment.
|contexts_service.replicas
|int
|`1`
|Number of replicas to deploy for the contexts-service deployment.
|cron_service.replicas
|int
|`1`
|Number of replicas to deploy for the cron-service deployment.
|dispatcher.replicas
|int
|`1`
|Number of replicas to deploy for the dispatcher deployment.
|distributor_cleaner.replicas
|int
|`1`
|Number of replicas to deploy for the distributor-dispatcher deployment.
|distributor_dispatcher.replicas
|int
|`1`
|Number of replicas to deploy for the distributor-dispatcher deployment.
|distributor_external.replicas
|int
|`1`
|Number of replicas to deploy for the distributor-external deployment.
|distributor_internal.replicas
|int
|`1`
|Number of replicas to deploy for the distributor-internal deployment.
|domain_service.replicas
|int
|`1`
|Number of replicas to deploy for the domain-service deployment.
|frontend.replicas
|int
|`1`
|Number of replicas to deploy for the frontend deployment.
|github
|object
| `{
  "clientId": "",
  "clientSecret": "",
  "enterprise": false,
  "fingerprint": null,
  "hostname": "ghe.example.com",
  "scheme": "https",
  "selfSignedCert": false,
  "unsafeDisableWebhookSSLVerification": false
}`
|VCS Configuration details (currently limited to Github Enterprise and Github.com)
|github.clientId
|string
|`""`
|Client ID for OAuth Login via Github (2 Options). Option 1: Set the value here and CircleCI will create the secret automatically. Option 2: Leave this blank, and create the secret yourself. CircleCI will assume it exists. Create on by Navigating to Settings > Developer Settings > OAuth Apps. Your homepage should be set to `{{ .Values.global.scheme }}://{{ .Values.global.domainName }}` and callback should be `{{ .Value.scheme }}://{{ .Values.global.domainName }}/auth/github`.
|github.clientSecret
|string
|`""`
|Client Secret for OAuth Login via Github (2 Options). Option 1: Set the value here and CircleCI will create the secret automatically. Option 2: Leave this blank, and create the secret yourself. CircleCI will assume it exists. Retrieved from the same location as specified in github.clientID.
|github.enterprise
|bool
|`false`
|Set to true for Github Enterprise and false for Github.com
|github.fingerprint
|string
|`nil`
|Required when it is not possible to directly ssh-keyscan a GitHub Enterprise instance. It is not possible to proxy `ssh-keyscan`.
|github.hostname
|string
|`"ghe.example.com"`
|Github hostname. Ignored on Github.com. This is the hostname of your Github Enterprise installation.
|github.scheme
|string
|`"https"`
|One of 'http' or 'https'. Ignored on Github.com. Set to 'http' if your Github Enterprise installation is not using TLS.
|github.selfSignedCert
|bool
|`false`
|set to 'true' If Github is using a self-signed certificate
|github.unsafeDisableWebhookSSLVerification
|bool
|`false`
|Disable SSL Verification in webhooks. This is not safe and shouldn't be done in a production scenario. This is required if your Github installation does not trust the certificate authority that signed your Circle server certificates (e.g they were self signed).
|global.container.org
|string
|`"circleci"`
|The registry organization to pull all images from, defaults to circleci.
|global.container.registry
|string
|`""`
|The registry to pull all images from, defaults to dockerhub.
|global.domainName
|string
|`""`
|Domain name of your CircleCI install
|global.imagePullSecrets[0].name
|string
|`"regcred"`
|
|global.license
|string
|`""`
|License for your CircleCI install
|global.scheme
|string
|`"https"`
|Scheme for your CircleCI install
|global.tracing.collector_host
|string
|`""`
|
|global.tracing.enabled
|bool
|`false`
|
|global.tracing.sample_rate
|float
|`1`
|
|insights_service.dailyCronHour
|int
|`3`
|Defaults to 3AM local server time.
|insights_service.hourlyCronMinute
|int
|`35`
|Defaults to 35 minutes past the hour.
|insights_service.isEnabled
|bool
|`true`
|Whether or not to enable the insights-service deployment.
|insights_service.replicas
|int
|`1`
|Number of replicas to deploy for the insights-service deployment.
|internal_zone
|string
|`"server.circleci.internal"`
|
|keyset
|object
|`{"encryption":"","signing":""}`
|Keysets (2 Options) used to encrypt and sign artifacts generated by CircleCI. You need these values to configure server. Option 1: Set the values keyset.signing and keyset.encryption here and CircleCI will create the secret automatically. Option 2: Leave this blank, and create the secret yourself. CircleCI will assume it exists. The secret must be named 'signing-keys' and have the keys; signing-key, encryption-key.
|keyset.encryption
|string
|`""`
|Encryption Key To generate an artifact ENCRYPTION key run: `docker run circleci/server-keysets:latest generate encryption -a stdout`
|keyset.signing
|string
|`""`
|Signing Key To generate an artifact SIGNING key run: `docker run circleci/server-keysets:latest generate signing -a stdout`
|kong.acme.email
|string
|`"your-email@example.com"`
|
|kong.acme.enabled
|bool
|`false`
|This setting will fetch and renew Let's Encrypt certs for you. It defaults to false as this only works when there's a valid DNS entry for your domain (and the app. sub domain) - so you will need to deploy with this turned off and set the DNS records first. You can then set this to true and run helm upgrade with the updated setting if you want.
|kong.debug_level
|string
|`"notice"`
|Debug level for Kong. Available levels: debug, info, warn, error, crit. Default is "notice".
|kong.replicas
|int
|`1`
|
|kong.resources.limits.cpu
|string
|`"3072m"`
|
|kong.resources.limits.memory
|string
|`"3072Mi"`
|
|kong.resources.requests.cpu
|string
|`"512m"`
|
|kong.resources.requests.memory
|string
|`"512Mi"`
|
|legacy_notifier.replicas
|int
|`1`
|Number of replicas to deploy for the legacy-notifier deployment.
|mongodb.architecture
|string
|`"standalone"`
|
|mongodb.auth.database
|string
|`"admin"`
|
|mongodb.auth.existingSecret
|string
|`""`
|
|mongodb.auth.mechanism
|string
|`"SCRAM-SHA-1"`
|
|mongodb.auth.password
|string
|`""`
|
|mongodb.auth.rootPassword
|string
|`""`
|
|mongodb.auth.username
|string
|`"root"`
|
|mongodb.fullnameOverride
|string
|`"mongodb"`
|
|mongodb.hosts
|string
|`"mongodb:27017"`
|MongoDB host. This can be a comma-separated list of multiple hosts for sharded instances.
|mongodb.image.tag
|string
|`"3.6.22-debian-9-r38"`
|
|mongodb.internal
|bool
|`true`
|Set to false if you want to use an externalized MongoDB instance.
|mongodb.labels.app
|string
|`"mongodb"`
|
|mongodb.labels.layer
|string
|`"data"`
|
|mongodb.options
|string
|`""`
|
|mongodb.persistence.size
|string
|`"8Gi"`
|
|mongodb.podAnnotations."backup.velero.io/backup-volumes"
|string
|`"datadir"`
|
|mongodb.podLabels.app
|string
|`"mongodb"`
|
|mongodb.podLabels.layer
|string
|`"data"`
|
|mongodb.ssl
|bool
|`false`
|
|mongodb.tlsInsecure
|bool
|`false`
|If using an SSL connection with custom CA or self-signed certs, set this to true
|mongodb.useStatefulSet
|bool
|`true`
|
|nginx.annotations."service.beta.kubernetes.io/aws-load-balancer-cross-zone-load-balancing-enabled"
|string
|`"true"`
|
|nginx.annotations."service.beta.kubernetes.io/aws-load-balancer-type"
|string
|`"nlb"`
|Use "nlb" for Network Load Balancer and "clb" for Classic Load Balancer see https://aws.amazon.com/elasticloadbalancing/features/ for feature comparison
|nginx.aws_acm.enabled
|bool
|`false`
|⚠️ WARNING: Enabling this will recreate frontend's service which will recreate the load balancer. If you are updating your deployed settings, then you will need to route your frontend domain to the new loadbalancer. You will also need to add `service.beta.kubernetes.io/aws-load-balancer-ssl-cert: <acm-arn>` to the `nginx.annotations` block.
|nginx.loadBalancerIp
|string
|`""`
|Load Balancer IP To use a static IP for the provisioned load balancer with GCP, set to a reserved static ipv4 address
|nginx.private_load_balancers
|bool
|`false`
|
|nginx.replicas
|int
|`1`
|
|nginx.resources.limits.cpu
|string
|`"3000m"`
|
|nginx.resources.limits.memory
|string
|`"3072Mi"`
|
|nginx.resources.requests.cpu
|string
|`"500m"`
|
|nginx.resources.requests.memory
|string
|`"512Mi"`
|
|nomad.auto_scaler.aws.accessKey
|string
|`""`
|AWS Authentication Config (3 Options). Option 1: Set accessKey and secretKey here, and CircleCI will create the secret for you. Option 2: Leave accessKey and secretKey blank, and create the secret yourself. CircleCI will assume it exists. Option 3: Leave accessKey and secretKey blank, and set the irsaRole field (IAM roles for service accounts).
|nomad.auto_scaler.aws.autoScalingGroup
|string
|`"asg-name"`
|
|nomad.auto_scaler.aws.enabled
|bool
|`false`
|
|nomad.auto_scaler.aws.irsaRole
|string
|`""`
|
|nomad.auto_scaler.aws.region
|string
|`"some-region"`
|
|nomad.auto_scaler.aws.secretKey
|string
|`""`
|
|nomad.auto_scaler.enabled
|bool
|`false`
|
|nomad.auto_scaler.gcp.enabled
|bool
|`false`
|
|nomad.auto_scaler.gcp.mig_name
|string
|`"some-managed-instance-group-name"`
|
|nomad.auto_scaler.gcp.project_id
|string
|`"some-project"`
|
|nomad.auto_scaler.gcp.region
|string
|`""`
|
|nomad.auto_scaler.gcp.service_account
|object
|`{"project_id":"... ...","type":"service_account"}`
|GCP Authentication Config (3 Options). Option 1: Set service_account with the service account JSON (raw JSON, not a string), and CircleCI will create the secret for you. Option 2: Leave the service_account field as its default, and create the secret yourself. CircleCI will assume it exists. Option 3: Leave the service_account field as its default, and set the workloadIdentity field with a service account email to use workload identities.
|nomad.auto_scaler.gcp.workloadIdentity
|string
|`""`
|
|nomad.auto_scaler.gcp.zone
|string
|`""`
|
|nomad.auto_scaler.scaling.max
|int
|`5`
|
|nomad.auto_scaler.scaling.min
|int
|`1`
|
|nomad.auto_scaler.scaling.node_drain_deadline
|string
|`"5m"`
|
|nomad.buildAgentImage
|string
|`"circleci/picard"`
|
|nomad.clients
|object
|`{}`
|
|nomad.server.gossip.encryption.enabled
|bool
|`true`
|
|nomad.server.gossip.encryption.key
|string
|`""`
|
|nomad.server.replicas
|int
|`3`
|
|nomad.server.rpc.mTLS
|object
|`{"CACertificate":"","certificate":"","enabled":false,"privateKey":""}`
|mTLS is strongly suggested for RPC communication. It encrypts traffic but also authenticates clients to ensure no unauthenticated clients can join the cluster as workers. Base64 encoded PEM encoded certificates are expected here.
|nomad.server.rpc.mTLS.CACertificate
|string
|`""`
|base64 encoded nomad mTLS certificate authority
|nomad.server.rpc.mTLS.certificate
|string
|`""`
|base64 encoded nomad mTLS certificate
|nomad.server.rpc.mTLS.privateKey
|string
|`""`
|base64 encoded nomad mTLS private key
|nomad.server.service.unsafe_expose_api
|bool
|`false`
|
|object_storage
|object
|`{"bucketName":"","expireAfter":0,"gcs":{"enabled":false,"service_account":{"project_id":"... ...","type":"service_account"},"workloadIdentity":""},"s3":{"accessKey":"","enabled":false,"endpoint":"https://s3.us-east-1.amazonaws.com","irsaRole":"","secretKey":""}}`
|Object storage for build artifacts, audit logs, test results and more. One of object_storage.s3.enabled or object_storage.gcs.enabled must be true for the chart to function.
|object_storage.expireAfter
|int
|`0`
|number of days after which artifacts will expire
|object_storage.gcs.service_account
|object
|`{"project_id":"... ...","type":"service_account"}`
|GCP Storage (GCS) Authentication Config (3 Options). Option 1: Set service_account with the service account JSON (raw JSON, not a string), and CircleCI will create the secret for you. Option 2: Leave the service_account field as its default, and create the secret yourself. CircleCI will assume it exists. Option 3: Leave the service_account field as its default, and set the workloadIdentity field with a service account email to use workload identities.
|object_storage.s3
|object
|`{"accessKey":"","enabled":false,"endpoint":"https://s3.us-east-1.amazonaws.com","irsaRole":"","secretKey":""}`
|S3 Configuration for Object Storage. Authentication methods: AWS Access/Secret Key, and IRSA Role
|object_storage.s3.accessKey
|string
|`""`
|AWS Authentication Config (3 Options). Option 1: Set accessKey and secretKey here, and CircleCI will create the secret for you. Option 2: Leave accessKey and secretKey blank, and create the secret yourself. CircleCI will assume it exists. Option 3: Leave accessKey and secretKey blank, and set the irsaRole field (IAM roles for service accounts), also set region: "your-aws-region".
|object_storage.s3.endpoint
|string
|`"https://s3.us-east-1.amazonaws.com"`
|API endpoint for S3. If in AWS us-west-2, for example, this would be the regional endpoint http://s3.us-west-2.amazonaws.com. If using S3 compatible storage, specify the API endpoint of your object storage server
|orb_service.replicas
|int
|`1`
|Number of replicas to deploy for the orb-service deployment.
|output_processor.replicas
|int
|`2`
|Number of replicas to deploy for the output-processor deployment.
|permissions_service.replicas
|int
|`1`
|Number of replicas to deploy for the permissions-service deployment.
|postgresql.auth.existingSecret
|string
|`""`
|
|postgresql.auth.password
|string
|`""`
|
|postgresql.auth.postgresPassword
|string
|`""`
|Password for the "postgres" admin user. Ignored if `auth.existingSecret` with key `postgres-password` is provided. If postgresql.internal is false, use auth.username and auth.password
|postgresql.auth.username
|string
|`""`
|
|postgresql.fullnameOverride
|string
|`"postgresql"`
|
|postgresql.image.tag
|string
|`"12.6.0"`
|
|postgresql.internal
|bool
|`true`
|
|postgresql.persistence.existingClaim
|string
|`""`
|
|postgresql.persistence.size
|string
|`"8Gi"`
|
|postgresql.postgresqlHost
|string
|`"postgresql"`
|
|postgresql.postgresqlPort
|int
|`5432`
|
|postgresql.primary.extendedConfiguration
|string
|`"max_connections = 500\nshared_buffers = 300MB\n"`
|
|postgresql.primary.podAnnotations."backup.velero.io/backup-volumes"
|string
|`"data"`
|
|prometheus.alertmanager.enabled
|bool
|`false`
|
|prometheus.enabled
|bool
|`false`
|
|prometheus.extraScrapeConfigs
|string
|`"- job_name: 'telegraf-metrics'\n  scheme: http\n  metrics_path: /metrics\n  static_configs:\n  - targets:\n    - \"telegraf:9273\"\n    labels:\n      service: telegraf\n"`
|
|prometheus.fullnameOverride
|string
|`"prometheus"`
|
|prometheus.nodeExporter.fullnameOverride
|string
|`"node-exporter"`
|
|prometheus.pushgateway.enabled
|bool
|`false`
|
|prometheus.server.emptyDir.sizeLimit
|string
|`"8Gi"`
|
|prometheus.server.fullnameOverride
|string
|`"prometheus-server"`
|
|prometheus.server.persistentVolume.enabled
|bool
|`false`
|
|proxy.enabled
|bool
|`false`
|If false, all proxy settings are ignored
|proxy.http
|object
|`{"auth":{"enabled":false,"password":null,"username":null},"host":"proxy.example.com","port":3128}`
|Proxy for HTTP requests
|proxy.https
|object
|`{"auth":{"enabled":false,"password":null,"username":null},"host":"proxy.example.com","port":3128}`
|Proxy for HTTPS requests
|proxy.no_proxy
|list
|`[]`
|List of hostnames, IP CIDR blocks exempt from proxying. Loopback and intra-service traffic is never proxied.
|pusher.key
|string
|`"circle"`
|
|pusher.secret
|string
|`"REPLACE_THIS_SECRET"`
|
|rabbitmq.auth.erlangCookie
|string
|`""`
|
|rabbitmq.auth.existingErlangSecret
|string
|`""`
|
|rabbitmq.auth.existingPasswordSecret
|string
|`""`
|
|rabbitmq.auth.password
|string
|`""`
|
|rabbitmq.auth.username
|string
|`"circle"`
|
|rabbitmq.fullnameOverride
|string
|`"rabbitmq"`
|
|rabbitmq.image.tag
|string
|`"3.8.14-debian-10-r10"`
|
|rabbitmq.podAnnotations."backup.velero.io/backup-volumes"
|string
|`"data"`
|
|rabbitmq.podLabels.app
|string
|`"rabbitmq"`
|
|rabbitmq.podLabels.layer
|string
|`"data"`
|
|rabbitmq.replicaCount
|int
|`1`
|
|rabbitmq.statefulsetLabels.app
|string
|`"rabbitmq"`
|
|rabbitmq.statefulsetLabels.layer
|string
|`"data"`
|
|redis.cluster.enabled
|bool
|`true`
|
|redis.cluster.slaveCount
|int
|`1`
|
|redis.fullnameOverride
|string
|`"redis"`
|
|redis.image.tag
|string
|`"6.2.1-debian-10-r13"`
|
|redis.master.podAnnotations."backup.velero.io/backup-volumes"
|string
|`"redis-data"`
|
|redis.podLabels.app
|string
|`"redis"`
|
|redis.podLabels.layer
|string
|`"data"`
|
|redis.replica.podAnnotations."backup.velero.io/backup-volumes"
|string
|`"redis-data"`
|
|redis.statefulset.labels.app
|string
|`"redis"`
|
|redis.statefulset.labels.layer
|string
|`"data"`
|
|redis.usePassword
|bool
|`false`
|
|schedulerer.replicas
|int
|`1`
|Number of replicas to deploy for the schedulerer deployment.
|serveUnsafeArtifacts
|bool
|`false`
|Warning! Changing this to true will serve HTML artifacts instead of downloading them. This can allow specially-crafted artifacts to gain control of users' CircleCI accounts.
|sessionCookieKey
|string
|`""`
|Session Cookie Key (2 Options). NOTE: Must be exactly 16 bytes. Option 1: Set the value here and CircleCI will create the secret automatically. Option 2: Leave this blank, and create the secret yourself. CircleCI will assume it exists.
|smtp
|object
|`{"host":"smtp.example.com","notificationUser":"builds@circleci.com","password":"secret-smtp-passphrase","port":25,"tls":true,"user":"notification@example.com"}`
|Email notification settings
|smtp.port
|int
|`25`
|Outbound connections on port 25 are blocked on most cloud providers. Should you select this default port, be aware that your notifications may fail to send.
|smtp.tls
|bool
|`true`
|StartTLS is used to encrypt mail by default. Only disable this if you can otherwise guarantee the confidentiality of traffic.
|soketi.replicas
|int
|`1`
|Number of replicas to deploy for the soketi deployment.
|telegraf.args[0]
|string
|`"--config"`
|
|telegraf.args[1]
|string
|`"/etc/telegraf/telegraf.d/telegraf_custom.conf"`
|
|telegraf.config.agent.interval
|string
|`"30s"`
|
|telegraf.config.agent.omit_hostname
|bool
|`true`
|
|telegraf.config.agent.round_interval
|bool
|`true`
|
|telegraf.config.custom_config_file
|string
|`""`
|
|telegraf.config.inputs[0].statsd.service_address
|string
|`":8125"`
|
|telegraf.config.outputs[0].prometheus_client.listen
|string
|`":9273"`
|
|telegraf.fullnameOverride
|string
|`"telegraf"`
|
|telegraf.image.tag
|string
|`"1.17-alpine"`
|
|telegraf.mountPoints[0].mountPath
|string
|`"/etc/telegraf/telegraf.d"`
|
|telegraf.mountPoints[0].name
|string
|`"telegraf-custom-config"`
|
|telegraf.mountPoints[0].readOnly
|bool
|`true`
|
|telegraf.rbac.create
|bool
|`false`
|
|telegraf.serviceAccount.create
|bool
|`false`
|
|telegraf.volumes[0].configMap.name
|string
|`"telegraf-custom-config"`
|
|telegraf.volumes[0].name
|string
|`"telegraf-custom-config"`
|
|test_results_service.replicas
|int
|`1`
|Number of replicas to deploy for the test-results-service deployment.
|tls.certificate
|string
|`""`
|base64 encoded certificate, leave empty to use self-signed certificates
|tls.privateKey
|string
|`""`
|base64 encoded private key, leave empty to use self-signed certificates
|vault
|object
|`{"image":{"repository":"circleci/vault-cci","tag":"0.4.196-1af3417"},"internal":true,"podAnnotations":{"backup.velero.io/backup-volumes":"data"},"token":"","transitPath":"transit","url":"http://vault:8200"}`
|External Services configuration
|vault.internal
|bool
|`true`
|Disables this charts Internal Vault instance
|vault.token
|string
|`""`
|This token is required when `internal: false`.
|vault.transitPath
|string
|`"transit"`
|When `internal: true`, this value is used for the vault transit path.
|vm_gc.replicas
|int
|`1`
|Number of replicas to deploy for the vm-gc deployment.
|vm_scaler.prescaled
|list
|`[{"count":0,"cron":"","docker-engine":true,"image":"docker-default","type":"l1.medium"},{"count":0,"cron":"","docker-engine":false,"image":"default","type":"l1.medium"},{"count":0,"cron":"","docker-engine":false,"image":"docker","type":"l1.large"},{"count":0,"cron":"","docker-engine":false,"image":"windows-default","type":"windows.medium"}]`
|Configuration options for, and numbers of, prescaled instances.
|vm_scaler.replicas
|int
|`1`
|Number of replicas to deploy for the vm-scaler deployment.
|vm_service.dlc_lifespan_days
|int
|`3`
|Number of days to keep DLC volumes before pruning them.
|vm_service.enabled
|bool
|`true`
|
|vm_service.providers
|object
|`{"ec2":{"accessKey":"","assignPublicIP":true,"enabled":false,"irsaRole":"","linuxAMI":"","region":"us-west-1","secretKey":"","securityGroupId":"sg-8asfas76","subnets":["subnet-abcd1234"],"tags":["key","value"],"windowsAMI":"ami-mywindowsami"},"gcp":{"assignPublicIP":true,"enabled":false,"linuxImage":"","network":"my-server-vpc","network_tags":["circleci-vm"],"project_id":"my-server-project","service_account":{"project_id":"... ...","type":"service_account"},"subnetwork":"my-server-vm-subnet","windowsImage":"","workloadIdentity":"","zone":"us-west2-a"}}`
|Provider configuration for the VM service.
|vm_service.providers.ec2.accessKey
|string
|`""`
|EC2 Authentication Config (3 Options). Option 1: Set accessKey and secretKey here, and CircleCI will create the secret for you. Option 2: Leave accessKey and secretKey blank, and create the secret yourself. CircleCI will assume it exists. Option 3: Leave accessKey and secretKey blank, and set the irsaRole field (IAM roles for service accounts).
|vm_service.providers.ec2.enabled
|bool
|`false`
|Set to enable EC2 as a virtual machine provider
|vm_service.providers.ec2.subnets
|list
|`["subnet-abcd1234"]`
|Subnets must be in the same availability zone
|vm_service.providers.gcp.enabled
|bool
|`false`
|Set to enable GCP Compute as a VM provider
|vm_service.providers.gcp.service_account
|object
|`{"project_id":"... ...","type":"service_account"}`
|GCP Compute Authentication Config (3 Options). Option 1: Set service_account with the service account JSON (raw JSON, not a string), and CircleCI will create the secret for you. Option 2: Leave the service_account field as its default, and create the secret yourself. CircleCI will assume it exists. Option 3: Leave the service_account field as its default, and set the workloadIdentityField with a service account email to use workload identities.
|vm_service.replicas
|int
|`1`
|Number of replicas to deploy for the vm-service deployment.
|web_ui.replicas
|int
|`1`
|Number of replicas to deploy for the web-ui deployment.
|web_ui_404.replicas
|int
|`1`
|Number of replicas to deploy for the web-ui-404 deployment.
|web_ui_insights.replicas
|int
|`1`
|Number of replicas to deploy for the web-ui-insights deployment.
|web_ui_onboarding.replicas
|int
|`1`
|Number of replicas to deploy for the web-ui-onboarding deployment.
|web_ui_org_settings.replicas
|int
|`1`
|Number of replicas to deploy for the web-ui-org-settings deployment.
|web_ui_project_settings.replicas
|int
|`1`
|Number of replicas to deploy for the web-ui-project-settings deployment.
|web_ui_server_admin.replicas
|int
|`1`
|Number of replicas to deploy for the web-ui-server-admin deployment.
|web_ui_user_settings.replicas
|int
|`1`
|Number of replicas to deploy for the web-ui-user-settings deployment.
|webhook_service.isEnabled
|bool
|`true`
|
|webhook_service.replicas
|int
|`1`
|Number of replicas to deploy for the webhook-service deployment.
|workflows_conductor_event_consumer.replicas
|int
|`1`
|Number of replicas to deploy for the workflows-conductor-event-consumer deployment.
|workflows_conductor_grpc.replicas
|int
|`1`
|Number of replicas to deploy for the workflows-conductor-grpc deployment.
|===

ifndef::pdf[]
[#next-steps]
== Next steps

* link:/docs/server/installation/hardening-your-cluster[Hardening Your Cluster]
* link:/docs/server/installation/migrate-from-server-3-to-server-4[Server 4.x Migration]
* link:/docs/server/operator/backup-and-restore[Backup & Restore]
endif::[]