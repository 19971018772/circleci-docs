---
contentTags:
  platform:
  - Cloud
---
= <<Re-run failed tests only>>
:page-layout: classic-docs
:page-liquid:
:page-description: <<Functionality to optimize running tests on CircleCI>>
:icons: font
:toc: macro
:toc-title:

[#motivation-and-introduction]
== Motivation and Introduction
Historically, when your testing job has flaky tests, the only option to get to a passing workflow was to link:https://support.circleci.com/hc/en-us/articles/360050303671-How-To-Rerun-a-Workflow[re-run your workflow from failed].  This type of re-run executes *all tests* from your testing job, including the tests that passed which prolongs time-to-feedback and burns credits unneccessarily.

CircleCI is releasing new preview functionality to **re-run failed tests only**.  When selecting this option (see image below), instead of re-running the *entire test suite* when a transient test failure arises, only a subset of tests are re-run.  This option re-runs failed tests from the same commit, not new ones.

**Insert screenshot**


[#prerequisites]
== Prerequisites

* Testing job uploads xref:collect-test-data/#[test results] to CircleCI.  `filename` or `classname` attributes **must be present** in the JUnit XML output
* Testing job uses `circleci tests run` (see below for details) to execute tests
  ** Note: If your current job is using xref:test-splitting-tutorial#[Intelligent test splitting], you must switch your `.circleci/config.yml` definition from `circleci tests split` to `circleci tests run` (see below for instructions)

[#quick-start]
== Quick-start

[#example-config-file-before]
=== Before: Example `.circleci/config.yml` file

```yaml
 - run:
    name: Run tests
    command: |
      mkdir test-results
      TEST_FILES=$(circleci tests glob "**/test_*.py" | circleci tests split --split-by=timings) \
      pytest --junitxml=test-results/junit.xml $TEST_FILES
      
- store_test_results
    path: test-results
```

A snippet of a basic CircleCI configuration file that splits tests by previous timing results (xref:test-splitting-tutorial#[Intelligent test splitting]), executes Python test files that end in `.py`, stores the test results in a new directory called `test-results`, and uploads those test results to CircleCI.  **Note:** `-o junit_family=legacy` is present to ensure that the test results being generated contain the `filename` attribute.  Not present in this snippet is the key to set `parallelism`(xref:parallelism-faster-jobs#[tutorial]).

[#example-config-file-after]
=== After: Example `.circleci/config.yml` file

```yaml
 - run:
    name: Run tests
    command: |
      mkdir test-results
      TEST_FILES=$(circleci tests glob "**/test_*.py")
      echo $TEST_FILES | circleci tests run --command="xargs pytest -o junit_family=legacy --junitxml=test-results/junit.xml" \
      --verbose \
      --split-by=timings

 - store_test_results
    path: test-results
```

[#breakdown-the-configuration]
==== Breakdown of the configuration

* `TEST_FILES=$(circleci tests glob "**/test_*.py")`
  ** This command uses CircleCI's xref:troubleshoot-test-splitting#video-troubleshooting-globbing[glob command] to provide a list of test files to the `circleci tests run` command as standard input (link:https://www.computerhope.com/jargon/s/stdin.htm[stdin]).  In this case, we're looking for any test file that starts with "test_" and ends with ".py".
  
* `echo $TEST_FILES |`
  ** Pass the list of test files to the `circleci tests run` command via `stdin`.

* `circleci tests run --command="xargs pytest -o junit_family=legacy --junitxml=test-results/junit.xml" --verbose --split-by=timings`
  ** Invoke `circleci tests run` and specify the original command used to run tests as part of the `--command=` parameter.  **This is required**.  `xargs` must be present as well.
  ** `--verbose` is an optional parameter for `circleci tests run` which enables more verbose debugging messages
  ** `--split-by-timings` accomplishes intelligent test splitting by timing for `circleci tests run`. Note that this is not required in order to use `circleci tests run`.  If your testing job is not using CircleCI's test splitting, omit this parameter.
  
[#verify-the-configuration]
==== Verify the configuration

After set-up, the next time that you encounter a test failure, click the "Re-run failed tests only" button. 

If the `--verbose` setting is enabled, you should see output similar to the following the next time you run this job on CircleCI:

```bash
Installing circleci-tests-plugin-cli plugin.
circleci-tests-plugin-cli plugin Installed. Version: 1.0.3349-470dac4
DEBU[2023-04-10T22:36:53Z] Attempting to read from stdin. This will hang if no input is provided. 
INFO[2023-04-10T22:36:53Z] starting batch execution                      batch_count=1 batches_processed=0 total_batches_for_job=3
DEBU[2023-04-10T22:36:53Z] received test names: test_api.py```
```

The job should only re-run tests that are from a `classname` of `filename` that had at least one test failure when the "Re-run failed tests only" button is clicked going forward.  If you're seeing different behavior, comment on this https://discuss.circleci.com/[Discuss post] for support.

[#additional-examples]
== Additional examples

**Configure a job running Ruby (rspec) tests to use "Re-run failed tests only"**:

First, add the following gem to your Gemfile:

```bash
gem 'rspec_junit_formatter'
```

Then, modify your test command to use `circleci tests run`:

```yaml
 - run: mkdir ~/rspec
 - run:
    command: |
      circleci tests glob spec/**/*_spec.rb | circleci tests run --command="xargs bundle exec rspec --format progress --format RspecJunitFormatter -o ~/rspec/rspec.xml" --verbose
 ```

Update the glob command to match your use case.  See xref:collect-test-data/#rspec#[rspec] for details on how to output test results in an acceptable format for `rspec`.

**Configure a job running Ruby (Cucumber) tests to use "Re-run failed tests only"**:

Modify your test command to look like something similar to:

```yaml
- run: mkdir -p ~/cucumber
- run:
    command: |
    circleci tests glob features/**/*.feature | circleci tests run --command="xargs bundle exec cucumber --format junit --out ~/cucumber/junit.xml" --verbose
 ```

Update the glob command to match your use case.  See xref:collect-test-data/#cucumber#[cucumber] for details on how to output test results in an acceptable format for `Cucumber`.

**Configure a job running Cypress tests to use "Re-run failed tests only"**:

1. Install dependencies `cypress-multi-reporters` and `mocha-junit-reporter`. If using `npm`, add to the file where dependencies are installed (ie. `package.json` or `reporter-config.json`:

```bash
npm install --save-dev cypress-multi-reporters mocha-junit-reporter
```

2. Create and setup reporter config file if it doesn't already exist, this example will call it `reporter-config.json`.

```bash
{
  "reporterEnabled": "spec, mocha-junit-reporter", // set the reporters
  "reporterOptions": {
    "mochaFile": "results/junit/junit-[hash].xml", // each suite produces its own junit :(, save them with unique hash
   }
}
```

3. Modify your test command to use the two reporter flags and `circleci tests run`:

```yaml
     -run:
        name: run tests
        command: | 
          cd ./cypress 
          npm ci 
          npm run start &
          circleci tests glob "cypress/**/*.cy.js" | circleci tests run --command="xargs npx cypress run --reporter cypress-multi-reporters --reporter-options configFile=reporter-config.json --spec" --verbose
 ```

4. Because Cypress does not output the expected `filename` attribute on its JUnit XML files, follow the steps outlined link:https://github.com/michaelleeallen/mocha-junit-reporter/issues/132[here] to massage the test results into the proper format.  In this case, we've saved a copy of the script to a file called `fix-junit.js`. You can then invoke this script by adding a new command (in addition to the command that uploads test results, `store_test_results`):

```yaml
    - run:
       when: always
       name: process test results (add in file path in junit)
       command: |
          cd ./cypress
          node ./scripts/fix-junit.js
     - store_test_results: 
       path: ./cypress/results
```  

**Configure a job running Javascript/Typescript (Jest) tests to use "Re-run failed tests only"**:

Modify your test command to look like something similar to:

```yaml
- run:
    command: |
    npx jest --listTests | circleci tests run --command="JEST_UNIT_ADD_FILE_ATTRIBUTE=true xargs npx jest --config jest.config.js --runInBand --"
    environment:
        JEST_JUNIT_OUTPUT_DIR: ./reports/
  - store_test_results:
      path: ./reports/
 ```

Update the `npx jest --listTests` command to match your use case.  See xref:collect-test-data/#jest#[jest] for details on how to output test results in an acceptable format for `jest`.  `JEST_UNIT_ADD_FILE_ATTRIBUTE=true` is added to ensure that the `filename` attribute is present.

[#known-limitations]
== Known limitations

* When re-running only the failed tests, the next time that job runs, test splitting by timing may not be as efficient as expected as the test results being stored are only from the subset of failed tests that were run
* Orbs that run tests *may* not work with this new fucntionality at this time
* If a shell script is invoked to run tests, `circleci tests run` should be placed in the *shell script* itself, not `.circleci/config.yml`
* Jobs that are older than the xref:persist-data/#custom-storage-usage[retention period] for Workspaces for the organization cannot be re-run with "Re-run failed tests only"

[#FAQs]
== FAQs

I have a question or issue, where do I go?

*Answer*: Insert Discuss post.

Will this functionality re-run individual tests?

*Answer*: No, it will re-run failed test `classnames` or `filenames` that had at least 1 individual test failure

What happens if I try to use the functionality and it hasn't been set-up in my `.circleci/config.yml` file?

*Answer*: The job will fail.

When can I click the option to "Re-run failed tests only?"

*Answer*: Right now, the option will be present anytime "Re-run workflow from failed" option is present and vice versa.

I don't see my test framework on this page, can I still use the functionality

*Answer*: Yes, as long as your job meets the prerequisites enumerated at the top of this document the functionality is test runner and test framework agnostic.  You can use xref:collect-test-data/#[Collect test data] to ensure that the job is uploading test results.  Note that `classname` and `filename` is not always present by default, it may require additional configuration.  From there, follow the "Quick-start" section to modify your test command to use `circleci tests run`.  If you run into issues, comment on this Discuss post (needs link).

Can I see in the UI whether a job was re-run using "Re-run failed tests only"

*Answer* Not at this time
